{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4f07f49574a8963c9b87cf8947d7fb36",
     "grade": false,
     "grade_id": "cell-513963dffd022dec",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Data Fundamentals (H)\n",
    "John H. Williamson -- Session 2018/2019\n",
    "\n",
    "----\n",
    "<font color=\"red\"> Read the submission instructions at the bottom of this notebook **carefully** before submitting </font> \n",
    "\n",
    "**This submission must be your own work; you will have to make a Declaration of Originality on submission.**\n",
    "\n",
    "Note that marks shown when tests pass are **provisional** and could change after grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Stuart Reilly\" ## fill these in \n",
    "STUDENT_ID = \"2258082R\"  ## e.g. 2222222"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 5: **Assessed**\n",
    "# Optimisation and gradient descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "It is recommended to keep the lecture notes open while doing this lab exercise.\n",
    "\n",
    "**This exercise is assessed and is marked out of 60**. Make sure you upload your solution by the deadline. See the notes at the bottom of this notebook for submission guidance.\n",
    "\n",
    "### Guidance\n",
    "This lab is structured like a worked tutorial, rather than an \"open\" exercise. Make sure you read the instructions carefully. There is less thinking but more reading required in this exercise than in previous labs.\n",
    "\n",
    "$$\\newcommand{\\vec}[1]{ {\\bf #1}} \n",
    "\\newcommand{\\real}{\\mathbb{R}}\n",
    "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
    "\\vec{x}\\real\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything imported OK\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "# Make sure you run this cell!\n",
    "from __future__ import print_function, division\n",
    "import numpy as np  # NumPy\n",
    "\n",
    "# custom utils\n",
    "from jhwutils.checkarr import array_hash, check_hash\n",
    "import jhwutils.image_audio as ia\n",
    "import jhwutils.tick as tick\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Set up Matplotlib\n",
    "import matplotlib as mpl   \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(\"Everything imported OK\")\n",
    "plt.rc('figure', figsize=(8.0, 4.0), dpi=140)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose of this lab\n",
    "This lab should help you:    \n",
    "* understand how optimisation can be used to solve approximation problems.\n",
    "* understand how learning can be seen as an optimisation problem.\n",
    "* use automatic differentiation to accelerate optimisation.\n",
    "\n",
    "You will implement a very simple form of **deep learning** in this lab, using first-order optimisation to learn an approximating function.\n",
    "\n",
    " If you find the concepts difficult, you might find this video helpful: [**How machines learn**](https://www.youtube.com/watch?v=IHZwWFHWa-w).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "You need to install `autograd`. The cell below will autoinstall this for you if the machine you are using does not already have it installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autograd succesfully imported. Everything OK. \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import autograd.numpy as np\n",
    "    from autograd import grad, elementwise_grad    \n",
    "    from autograd.misc.flatten import flatten\n",
    "    print(\"autograd succesfully imported. Everything OK. \")\n",
    "except:\n",
    "    # couldn't import, install the package\n",
    "    print(\"autograd not found.\\nInstalling autograd from git...\")\n",
    "    !pip install --no-cache --user https://github.com/HIPS/autograd\n",
    "    print(\"Please restart the kernel (Kernel/Restart) and run the import cells again.\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: gradient descent\n",
    "\n",
    "## Background\n",
    "\n",
    "If you are unsure about objective functions, read [the supplement](week_6_optimisation_i_supplement_objective_functions.ipynb) or the first part of the lecture notes from Unit 6.\n",
    "\n",
    "* An optimisation *problem* has **parameters**, (possibly) **constraints** and an **objective function**.\n",
    "\n",
    "* An optimisation *algorithm* has **hyperparameters** which determine how the search for the best parameter setting is conducted (for example, how big of a step to take when trying to move down the gradient of a function).\n",
    "\n",
    "* We will be working with **differentiable** objective functions, where we can compute the gradient of the function at any point, and use this information to quickly move towards the minimum.\n",
    "\n",
    "### Simple optimisation\n",
    "\n",
    "Suppose we have a 4D parameter space ($\\theta \\in \\real^4$), and an objective function $$L(\\theta) = \\sum_i (\\theta_i-i)^2$$\n",
    "\n",
    "We can write this in code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l(theta):\n",
    "    i = np.arange(len(theta)) # 0, 1, 2, ...\n",
    "    return np.sum((theta-i)**2) # sum of squares difference  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.79\n"
     ]
    }
   ],
   "source": [
    "# some random point\n",
    "theta_0 =  np.array([0.1, 0.2, 0.3, -0.5])\n",
    "\n",
    "# compute loss (objective function value) at this point\n",
    "print(l(theta_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How could we find the value where this objective function has a minimum -- the setting of $\\theta$ that minmises $L(\\theta)$? The answer is possibly obvious by inspection (it's the vector $[0,1,2,3]$), but assume we didn't already know this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random search: guessing solutions\n",
    "One solution would be to use purely random search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(l, max_iters, guess_fn):\n",
    "    best_guess, best_loss = None, None    \n",
    "    for i in range(max_iters):\n",
    "        # random guess\n",
    "        guess = guess_fn()\n",
    "        loss = l(guess) # work out how bad it is\n",
    "        # check if we beat the record\n",
    "        if best_loss is None or l(guess)<best_loss:\n",
    "            best_loss = l(guess)\n",
    "            best_guess = guess\n",
    "    return best_guess\n",
    "\n",
    "# guess a vector between -10 and 10, with 4 elements \n",
    "def guess():\n",
    "    return np.random.uniform(-10, 10, 4) \n",
    "\n",
    "\n",
    "np.random.seed(2018)\n",
    "# try 10 repetitions\n",
    "for i in range(10):\n",
    "    result =  random_search(l, 10000, guess)\n",
    "    print(\"Best random guess {guess}, loss {loss:.2f}\".format(guess=result, loss=l(result)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hill climbing\n",
    "This does not work very well, and does not ever closely approximate the vector `[0,1,2,3]`. But the space of the objective function is continuous and our objective function might also be continuous. This means we could take advantage of the continuity; a small change in our parameters might lead to a small change in the objective function.\n",
    "\n",
    "**Task A.1** Write code to do hill-climbing search, instead of pure random search. Adjust the parameterisation of the search until the tests pass (this should be relatively easy). Note that the test will test against a **random** target; you can't hardcode the solution to just return `[0,1,2,3]`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "fc29e6809ca142e82f26e10e5eb99336",
     "grade": false,
     "grade_id": "cell-cda2614894aa7b73",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# you will have to define a function\n",
    "# to make a random small modification to \n",
    "# a guess called `neighbour`\n",
    "\n",
    "def hill_climbing(l, max_iters, guess_fn, neighbour_fn):    \n",
    "    current = guess_fn(l)\n",
    "    best = None\n",
    "    for i in range(max_iters):\n",
    "        neighbours = neighbour_fn(current)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing hill-climbing\n",
    "The code below will test your solution. It should be apparent that hill climbing does a much better job, getting to a good solution within 5000 iterations.\n",
    "\n",
    "You must have defined functions:\n",
    "    \n",
    "* `hill_climbing`\n",
    "* `guess` (returns a random guess)\n",
    "* `neighbour` (returns a modification of a current estimate for theta)\n",
    "\n",
    "How you implement and use these is up to you.\n",
    "\n",
    "The hill climbing optimiser should expect to optimise a 4 element parameter vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "db6b1f57682f2be0fe1e0cab698c6e97",
     "grade": true,
     "grade_id": "cell-e84092f988d1db33",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# try 10 times\n",
    "with tick.marks(4):\n",
    "    np.random.seed(2018)\n",
    "    passed = True\n",
    "    for i in range(10):\n",
    "        target = np.random.uniform(0,4,4)\n",
    "        # use a random target :)\n",
    "        def custom_l(theta):\n",
    "            return np.sum((theta-target)**2)          \n",
    "        # 5000 iterations\n",
    "        result = hill_climbing(custom_l, 5000, guess, neighbour)\n",
    "        difference = custom_l(result)               \n",
    "        print(\"Loss on run {i} is {loss:.2e}\".format(i=i, loss=difference))        \n",
    "        if difference>0.1:\n",
    "            passed = False\n",
    "    assert(passed)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beyond continuity: differentiability \n",
    "Having a continuous objective function made it easy to optimise this solution, compared to having to use pure random search. We can do much better, however.\n",
    "\n",
    "If we can differentiate `l` then we can use **gradient descent** to solve the problem, using the algorithm:\n",
    "\n",
    "$$\\vec{\\theta^{(i+1)}} = \\vec{\\theta^{(i)}} - \\delta \\nabla L(\\vec{\\theta^{(i)}})$$\n",
    "\n",
    "`autograd` makes this trivially easy, and can automatically compute the derivatives of our code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute gradient of l with respect to theta\n",
    "grad_l = grad(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be a vector, with as many dimensions has theta\n",
    "print(grad_l(theta_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a **vector** which points in the direction where the objective function should be decreasing. We can try moving a small amount in this direction, computing the loss as we go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.array(theta_0)\n",
    "delta = 0.2 # how big of steps to take\n",
    "\n",
    "for i in range(15):\n",
    "    theta = theta - delta * grad_l(theta)\n",
    "    print(\"Loss:\", l(theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This quickly reduces the objective function value, and gets very close to the true solution. While hill-climbing took thousands of iterations, and random search never got close to a good solution, this approach finds a very precise solution in only 15 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(theta) # should be close to [0,1,2,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B: The face direction  problem\n",
    "Given an image of a head, like the rendering of the statue below, can we predict how it is oriented in space, *directly from the pixels*? For example, the image below:\n",
    "\n",
    "<img src=\"new_data/face_0000.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is the same face, but a different orientation (or *pose*) to this one:\n",
    "\n",
    "<img src=\"new_data/face_0001.png\">\n",
    "\n",
    "We can characterise the pose in terms of the:\n",
    "\n",
    "* *elevation* (head tilting with chin up/down) and\n",
    "* *azimuth* (head rotating left to right)\n",
    "\n",
    "The images above have similar elevation (the noses are roughly level in both pictures), but the azimuths are very different.\n",
    "\n",
    "How can we use optimisation to solve this problem? We need to have a *parameterisable function* that somehow maps from images to poses, and then adjust the parameters until the function maps face images onto poses. That is, we want to find some function $f$ that takes an image as input, and outputs a face poses as output. $f$ must be configurable with a vector of parameters $\\theta$.\n",
    "\n",
    "* $\\vec{x}$ will be the face image, represented as a simple vector, by unravelling the image\n",
    "* $y$ will be the predicted face pose, as a scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approximation\n",
    "We will be trying to approximate a function. This means we have an objective function of the form:\n",
    "\n",
    "$$L(\\theta) = \\|f(\\vec{x};\\theta)-y\\|$$\n",
    "\n",
    "where we measure the difference between a predicted output $f(\\vec{x};\\theta)$ and a real, expected output $y$, and try and minimise that difference by choosing a good setting for $\\theta$.\n",
    "\n",
    "We will build a simple \"deep learning\" system. We will completely ignore many of the important problems in machine learning, like overfitting, regularisation, efficient network architectures and fair evaluation,  and concentrate on using first-order optimisation to find a function that approximates a known transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "There are 698 images of a face in different poses in the file `new_data/face_strip.png`. The faces are 64x64 grayscale images, and\n",
    "have been stacked into one very long strip.\n",
    "    \n",
    "You can load an image with `ia.load_image_gray()`, as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single example image\n",
    "# *must* divide by 65535.0 to normalise the result\n",
    "face_img = ia.load_image_gray('new_data/face_0000.png') / 65535.0\n",
    "print(face_img.shape)\n",
    "ia.show_image_mpl(face_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load the data\n",
    "\n",
    "**Task B.1**\n",
    "\n",
    "* Load the face data from `face_strip.png` into a single tensor `faces`.\n",
    "* Reshape/rearrange it to a 698x64x64 tensor, and then slice it to take *every second* row and column of each image, giving a 698x32x32 tensor `faces`.\n",
    "* Normalize it to 0.0-1.0, as above.\n",
    "* Use `np.loadtxt` to load the file `new_data/face_pose_degrees.txt` as an 2x698 and transpose it into a 698x2 array `face_poses`. This contains the known orientations of the faces, *in the same order as the faces on the strip*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2f93e3131e8fe5c12b1afbb9955c2acc",
     "grade": false,
     "grade_id": "cell-856c82d82f1a2413",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did this correctly, you'll see a low-res face animation when you run the code below. The animation will jump around apparently random poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.show_gif(faces[0:10,:,:], width=\"100px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a2ecd1461aafe1998b14f610665ed530",
     "grade": true,
     "grade_id": "cell-336b17fa94ae2220",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "with tick.marks(3):\n",
    "    print(array_hash(faces))\n",
    "    assert(check_hash(faces, ((698, 32, 32), 87092746113.97925)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "00db05efbbbf65cfcff23993cdfce60d",
     "grade": true,
     "grade_id": "cell-de4c33d71a363e15",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "with tick.marks(1):\n",
    "    print(array_hash(face_poses))\n",
    "    assert(check_hash(face_poses, ((698, 2), -1401906.2345336243)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image vectors\n",
    "\n",
    "We have to be able to write this problem in the form:\n",
    "\n",
    "$$L(\\theta) = \\|f(\\vec{x};\\theta)-\\vec{y}\\|$$\n",
    "\n",
    "Every input vector $\\vec{x}$ must have a corresponding matched expected output $\\vec{y}$, and we need a function $f$ that depends on $\\vec{x}$ and $\\theta$.\n",
    "\n",
    "### Inputs\n",
    "What is $\\vec{x}$? How can we define the input to this function? We need to have one vector per example; that is a matrix with one row per face image. We can do this by reshaping the `faces` tensor to unravel the 32x32 pixel image into a single 1024 dimensional vector.\n",
    "\n",
    "Each image is then represented a single point in a 1024 dimensional space; the space of all 32x32 grayscale images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task B.2**\n",
    "Reshape the face tensor to a 698*1024 matrix; each row being a face image as a single \"unravelled\" vector. Store this in `face_inputs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7ad2019465ace28d98f170cee41332c9",
     "grade": false,
     "grade_id": "cell-a36b7c1088b2943a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "15c13898b74af8e1b436ab2e8fbc2d36",
     "grade": true,
     "grade_id": "cell-49d00f27f546e4cf",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "with tick.marks(4):\n",
    "    print(array_hash(face_inputs))\n",
    "    assert(check_hash(face_inputs,((698, 1024), 87092746113.97925)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The expected outputs\n",
    "$\\vec{y}$ will be the *known* face orientation for each image. This is the data in `face_poses`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network we will define will map all predictions to the range [-1,1], so $\\vec{y}$ must be scaled to be in this range. The face orientations are currently stored in *degrees*.\n",
    "\n",
    "**Task B.3**\n",
    "\n",
    "Rescale `face_poses` by dividing it by 180.0 and storing the result in `expected_face_orientations`. This will reduce the maximum and minimum values to well inside the range [-1, 1].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b99ffd44f4b32b072a90c1f4e7a4423a",
     "grade": false,
     "grade_id": "cell-9a6358c28d3ed9d0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0dfd2bf78824aae67d851dec81ae037e",
     "grade": true,
     "grade_id": "cell-841bb2715828b076",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Min pose value:{min}, max pose value:{max}\".format(min=np.min(expected_face_orientations), max=np.max(expected_face_orientations)))\n",
    "\n",
    "with tick.marks(4):\n",
    "    print(array_hash(expected_face_orientations))\n",
    "    assert(check_hash(expected_face_orientations, ((698, 2), -7788.3679696312465)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done this correctly, you will see the faces laid out below, where the position the face is plotted corresponds to the orientation of the face:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_faces(images, positions):\n",
    "    # show the faces, and their orientations\n",
    "    fig = plt.figure(dpi=200)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.set_facecolor('k')\n",
    "    sz = 0.025\n",
    "    for i in range(0,len(positions),4):\n",
    "        pos = positions[i]\n",
    "        \n",
    "        # show the image at the output position\n",
    "        ax.imshow(images[i].reshape(faces.shape[1],faces.shape[2]), \n",
    "                  extent=[pos[0]-sz, pos[0]+sz, -pos[1]*8-sz, -pos[1]*8+sz],\n",
    "                  vmin=0, vmax=1, cmap='gray')\n",
    "        \n",
    "    ax.axhline(0, lw=1)\n",
    "    ax.axvline(0, lw=1)\n",
    "    ax.text(0,0.55, '+Elevation', color='w', fontdict={\"fontsize\":6})\n",
    "    ax.text(0,-0.55, '-Elevation', color='w', fontdict={\"fontsize\":6})\n",
    "    ax.text(0.42,0.0, '+Azimuth', color='w', fontdict={\"fontsize\":6})\n",
    "    ax.text(-0.55,0.0, '-Azimuth', color='w', fontdict={\"fontsize\":6})\n",
    "    ax.set_xlim(-0.6,0.6)\n",
    "    ax.set_ylim(-0.6,0.6)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(\"Face orientations\")\n",
    "    \n",
    "# apply to the *known* inputs and outputs\n",
    "show_faces(face_inputs, expected_face_orientations)\n",
    "plt.gca().set_title(\"True face orientations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A deep network\n",
    "How will this parameterisable function that maps from images to orientations be defined? We will use a very simple deep \"neural network\" predictor. This is an incredibly simple algorithm. It takes a vector, then repeatedly:\n",
    "\n",
    "* adds a small constant\n",
    "* takes the `tanh()` of the resulting vector; this simply squashes all the elements of the vector so they lie in the range [-1,1]\n",
    "* multiplies the vector by a (different) matrix\n",
    "\n",
    "We have to define the *shape* of each of the matrices which will be used to transform the vector, but we *optimise* to find the elements that go into those matrices. This is the \"learning\" part.\n",
    "\n",
    "Each of these steps is traditionally called a \"layer\" of the prediction function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a very basic neural network\n",
    "# the only slightly subtle thing is the unflattening, which is explained below\n",
    "def predict(x, theta, unflatten):        \n",
    "    for w in unflatten(theta):          \n",
    "        x = w.T @ np.tanh(x + 0.1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattening and unflattening\n",
    "**READ THIS CAREFULLY**\n",
    "\n",
    "To be able to optimise this prediction function in the standard form, we have to package *all* of the things that could vary into a single \"flat\" parameter vector $\\theta$. `predict()` can unpack a list of matrices from a single vector if it is given the right `unflatten` parameter.\n",
    "\n",
    "We can use the `flatten` convenience function to make this easy.\n",
    "\n",
    "    theta, unflatten = flatten(list_of_matrices)\n",
    "\n",
    "takes a list of matrices `list_of_matrices` and returns them packed into a single 1D NumPy vector `theta` along with `unflatten`, a function which will reverse that process and unpack all the matrices when applied to `theta`.\n",
    "\n",
    "`flatten` is like a \"super-ravel\" which can be reversed by the `unflatten` function which it returns. See the examples below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of matrices\n",
    "list_of_matrices = [np.zeros((3,3)), np.ones((2,4)), np.full((1,4), 2.0)]\n",
    "print(list_of_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to a flat vector\n",
    "# along with a *function* which will later unflatten theta back into a list of matrices\n",
    "theta, unflatten = flatten(list_of_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the flattened version; a single vector\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore the flattened version to original shapes\n",
    "print(unflatten(theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective function\n",
    "\n",
    "**Task B.4**\n",
    "\n",
    "Write an objective function that will compare the predicted output to the expected output, for one set of input and output vectors, given `theta`, `unflatten`, `x` and `y`. Use the $L_2$ norm. The function should be of the form\n",
    "\n",
    "    def face_loss(theta, unflatten, x, y):\n",
    "        ...\n",
    "        return l # a scalar\n",
    "        \n",
    "The loss function will need to call `predict` to calculate `y_prime`, the predicted output to compare with `y`. Assume `x` and `y` are vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e8d914100361c6eae1805372206286ea",
     "grade": false,
     "grade_id": "cell-305c064d9cca8eed",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def face_loss(theta, unflatten, x, y):\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "211cc7ac4905a71c56d6f82d9db5cbd8",
     "grade": true,
     "grade_id": "cell-abd9b2a75fa74b9c",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_network = [np.array([[1,0.5,-0.5], [0.0, 2.0, -1.0]]).T, \n",
    "                np.array([[2.0, 1.0], [1.0, -1.0]]).T]\n",
    "test_theta, test_unflatten = flatten(test_network)\n",
    "      \n",
    "with tick.marks(4):\n",
    "    assert(abs(face_loss(test_theta, test_unflatten, np.array([1,2,3]), np.array([-1, 1]))-3.37)<0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network architecture\n",
    "The choice of the matrix shapes we use to do the prediction affects how well we will be able to model the transformation.\n",
    "\n",
    "In our example, we know we have 1024 dimensional inputs (32x32 face images unraveled into flat vectors) and 2 dimensional outputs (the pose vectors). So the we must start with 1024 dimensional vectors and end up with 2 dimensional vectors. \n",
    "\n",
    "However, we can introduce any number of intermediate matrices into the prediction function. This gives more parameters that could be tweaked, and more flexibility in how the mapping is learned; it makes the prediction function more *flexible*. If we have more intermediate matrices, we can \"warp space\" more vigorously.\n",
    "\n",
    "A very simple model might have a single 1024,2 matrix; this would be a simple linear transformation of the inputs.\n",
    "\n",
    "A more complex model might have a mapping with four matrices in sequence:\n",
    "\n",
    "    W[0]     W[1]      W[2]   W[3]\n",
    "    1024,32 -> 32,16 -> 16,8 -> 8,2\n",
    "\n",
    "This \"architecture\" maps the 1024 dimensional input vector to some 32 dimensional space, then to some 16 dimensional space, then to some 8 dimensional space, then to the 2 dimensional output. Every matrix has to have an output dimension which matches the input dimension of the following matrix. The matrices W[0], W[1], W[2], W[3]  specify how the vector at each layer gets mapped to the next layer.\n",
    "\n",
    "These sizes of these matrices are pretty much arbitrarily chosen here. They could have been 1024->50->20->2 or 1024->10->10->10->10->10->15->2 or many other variations. These all represent different kind of functions that can be learned, but this the specific choice turns out not to be critical. More matrices with more elements means a more flexible function which can learn more complicated things; but will be harder to optimise efficiently.\n",
    "\n",
    "We *don't know* what values should go into these matrices; they specify some unknown transformation of the vectors in each step. We have to optimise to find the elements of these matrices. We will *discover* a warping of space from the space of images onto the space of poses. For this lab, assume that the matrix shapes to be used are:\n",
    "\n",
    "    1024,32  32,16  16,8  8,2\n",
    "\n",
    "This will work well, without being too hard to optimise. You can alter this if you want, but the above version is known to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialisation\n",
    "\n",
    "**Task B.5**\n",
    "We need to set up some *initial conditions* for the optimisation process. We can define the shape of each matrix, but we don't know what the values of the elements in the matrices should be. So we just make a random guess.\n",
    "\n",
    "* Create a function that generates initial conditions for the prediction function. \n",
    "* This function should take a list of matrix *shapes*, and create a corresponding list of randomly filled matrices.  \n",
    "* Each matrix generated should have the specified shape.  \n",
    "* The function should take a parameter `sigma` that should specify the spread of the random values chosen.\n",
    "\n",
    "Use `np.random.normal(0, sigma, shape)` to generate the random numbers.\n",
    "\n",
    "Return the **flattened** version of the matrix list, along with the corresponding `unflatten` function.\n",
    "\n",
    "Your function should have the form:\n",
    "    \n",
    "    def initial_conditions(shape_list, sigma):\n",
    "        ...\n",
    "        return theta, unflatten        \n",
    "\n",
    "For example `initial_conditions([[2,3], [3,6]], 0.1)` should return the flattened version of a `(2,3)` and `(3,6)` shape random matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7c6c20e6fbd0833ef3d3672e8cede36a",
     "grade": false,
     "grade_id": "cell-8dfaf31ad60c100b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9febc7f32b6ddf337ff28c5d4d888774",
     "grade": true,
     "grade_id": "cell-bf823cf97e49e7bf",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_theta, test_unflatten = initial_conditions([[8,4], [4,8], [2,4]], 0.1)\n",
    "matrices = test_unflatten(test_theta)\n",
    "with tick.marks(4):\n",
    "    assert(matrices[0].shape==(8,4))\n",
    "    assert(matrices[1].shape==(4,8))\n",
    "    assert(matrices[2].shape==(2,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random predictions\n",
    "We can use predict to see the effect of applying this function to the face images. Since all of the matrices are random, the result will be a random mess, where the positions plotted have no relation to the true orientations of the faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some test initial conditions\n",
    "random_theta, unflatten = initial_conditions( [[1024,32], [32, 16],  [16, 8], [8,2]], 0.2)\n",
    "# predict the outputs (will be random junk)\n",
    "predicted_outputs = [predict(face_inputs[i], random_theta, unflatten) for i in range(698)]\n",
    "show_faces(face_inputs, np.array(predicted_outputs))\n",
    "plt.gca().set_title(\"Random face orientations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task B.6** Write a function `total_face_loss` that computes the sum of the objective function value for *every* matched input and output pair from `face_inputs` and `expected_face_orientations`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3a3bf9c1e535c162ad861b8d5df985c5",
     "grade": false,
     "grade_id": "cell-a52fc79c200b3f58",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# compute the sum of losses\n",
    "# for every pair of xs and ys\n",
    "def total_face_loss(theta, unflatten):\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c061cd26ad075001ec6e02fec790c1ef",
     "grade": true,
     "grade_id": "cell-cbef7ebe8bc09215",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(2018)\n",
    "# create some test initial conditions\n",
    "random_theta, random_unflatten = flatten([np.random.normal(0,1,(1024,4)), np.random.normal(0,1,(4,2))])\n",
    "with tick.marks(2):\n",
    "    assert(np.allclose(total_face_loss(random_theta, random_unflatten), 1552.8832, atol=1e-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hill-climbing search\n",
    "    \n",
    "You now have enough to build a very basic optimiser. \n",
    "\n",
    "**Task B.7** Implement hill-climbing search to find a set of parameters that produces a better layout than the above version. Note that you will need to return both your optimised `theta` and the `unflatten` required to shape it back into a sequence of matrices.\n",
    "\n",
    "You already have `initial_conditions` that will produce an initial guess. Write a function to adjust the parameter vector by a small random variation. Then adapt your hill climbing code from above to try and optimise the mapping of face images to face orientations. Use `total_face_loss` to compute the objective function summed over every image example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8948e97c7eecd53efe4d6bc671e058e8",
     "grade": false,
     "grade_id": "cell-d11024a7368ea627",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def hill_climbing(l, max_iters, guess_fn, neighbour_fn):    \n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "18e8eb5690b8e508d1fcd455e6391dcf",
     "grade": true,
     "grade_id": "cell-05b61fcdd6bd9f43",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(2018)\n",
    "\n",
    "# you will need to define face_guess and face_neighbour\n",
    "result,  unflatten = hill_climbing(total_face_loss, 250, face_guess, face_neighbour)\n",
    "\n",
    "print(\"Loss in prediction {loss}\".format(loss=total_face_loss(result, unflatten)))\n",
    "\n",
    "with tick.marks(4):\n",
    "    assert(total_face_loss(result, unflatten)<120)\n",
    "    \n",
    "# predict the outputs (will be random junk)\n",
    "predicted_outputs = [predict(face_inputs[i], result, unflatten) for i in range(698)]\n",
    "show_faces(face_inputs, np.array(predicted_outputs))\n",
    "plt.gca().set_title(\"Hill climbed face orientation predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent learning\n",
    "\n",
    "Hill climbing gives some kind of result, but it is not very satisfactory -- although it is still quite impressive that we can learn an approximate face orientation predictor by randomly twiddling some values in a collection of matrices.\n",
    "\n",
    "Now we will optimise with gradient descent, and get a much better result.  In this task, you will have to define a function `sgd_learn`. This will perform a simple form of (stochastic) gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task B.8** Using automatic differentiation provided by `autograd`, compute the derivative of this loss function, and call it `grad_face_loss`. Hint: this is trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a03793b1200ee789b6397b9f26e960b8",
     "grade": false,
     "grade_id": "cell-1bb574a4d0ad2c73",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "16598a1aa9e296e4587134276f87e1be",
     "grade": true,
     "grade_id": "cell-50d46d06692fc999",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "flat, unflatten = flatten(np.array([1,2,3]))\n",
    "test_network = [np.array([[1,0.5,-0.5], [0.0, 2.0, -1.0]]).T, \n",
    "                np.array([[2.0, 1.0], [1.0, -1.0]]).T]\n",
    "test_theta, test_unflatten = flatten(test_network)\n",
    "\n",
    "with tick.marks(4):\n",
    "    assert(abs(np.sum(grad_face_loss(test_theta, test_unflatten, np.array([1,2,3]), np.array([-1, 1])))-4.479)<0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task B.9** \n",
    "\n",
    "Now we must define a function to perform stocahstic gradient descent.\n",
    "\n",
    "`sgd_learn` should:\n",
    "\n",
    "* take a list of matrix `shapes`, a `sigma` to specify the random initialisation of those matrices, a `step` size and a number of `iterations`\n",
    "* generate an initial `theta` from that set of shapes, using the `initial_condition()` function you defined above.\n",
    "* for each of the given number of iterations\n",
    "    * randomly select *ONE* input vector (from `inputs`) and matching output vector (from `outputs`).\n",
    "    * compute the gradient of the objective function for that image/output pair\n",
    "    * make a step, adjusting `theta` in the direction of this gradient, scaled by the step size\n",
    "    * print the iteration count every 500 iterations so you can see that the function is running\n",
    "correctly. \n",
    "\n",
    "* return the flattened vector and the corresponding unflatten function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function definition should look like:\n",
    "\n",
    "        def sgd_learn(shapes, inputs, outputs, sigma, step, iters):\n",
    "            ...        \n",
    "            return theta, unflatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: You don't need to implement *any* sophistications like momentum or random restart. You don't need to collect the data into minibatches. The algorithm you implement should be very simple. \n",
    "\n",
    "* You may also want to evaluate the objective function itself at each iteration, and print out the sum of the objective function value overs the last 100 iterations in your print statement (this is optional, but helps in tuning the performance; the number should go down as optimisation progresses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7b61c989fbb243e39abcf8c70ac0cd8f",
     "grade": false,
     "grade_id": "cell-1548bffbe7a4d279",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def sgd_learn(shapes, inputs, outputs, sigma=0.1, step=0.1, iters=10000):\n",
    "    # YOUR CODE HERE\n",
    "    return w, unflatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4033dfe1fc3401b07625de94a847ddb7",
     "grade": true,
     "grade_id": "cell-c5e1dcc9c57d02d0",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# verify that the shapes come out right\n",
    "with tick.marks(2):\n",
    "    test_theta, test_unflatten = sgd_learn([[1024,2]], face_inputs, expected_face_orientations, 0.1, 0.1, 1)\n",
    "    unflattened = test_unflatten(test_theta)\n",
    "    assert(len(unflattened)==1)\n",
    "    assert((unflattened[0].shape)==(1024,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "44d9879d7806163e0101a273d2db1819",
     "grade": true,
     "grade_id": "cell-53b4afa114ae3fd2",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## verify that some learning happens\n",
    "with tick.marks(4):\n",
    "    test_theta, test_unflatten = sgd_learn([[1024,2]], face_inputs, expected_face_orientations, 0.01, 0.001, 0)\n",
    "    before_losses = [face_loss(test_theta, test_unflatten, x,y) for x,y in zip(face_inputs, expected_face_orientations)]\n",
    "    test_theta, test_unflatten = sgd_learn([[1024,2]], face_inputs, expected_face_orientations, 0.02, 0.001, 200)\n",
    "    after_losses = [face_loss(test_theta, test_unflatten, x,y) for x,y in zip(face_inputs, expected_face_orientations)]\n",
    "    print(\"Mean loss before optimising %.2f; after optimising %.2f\" % (np.mean(before_losses),  np.mean(after_losses)))\n",
    "    assert(np.mean(after_losses)-np.mean(before_losses)<-0.01)\n",
    "    print(\"Something was learned!\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task B.10**\n",
    "\n",
    "Use this function to learn an approximate mapping from face images to 2D vectors. You will have to choose:\n",
    "* a **step size** (values in the range 0.1 to 0.0001 are reasonable)\n",
    "* the **sigma** for the initial conditions (values in the range 0.5 to 0.005 are reasonable).\n",
    "\n",
    "These are **hyperparameters** of the optimisation process. \n",
    "\n",
    "* You should use *no more* than 20000 iterations in the learning process. \n",
    "\n",
    "**Warning: if your call to `sgd_learn` takes more than ten minutes to run, the autograder will not accept your result!**\n",
    "\n",
    "Use `[[1024,32], [32, 16],  [16, 8], [8,2]]` as the list of shapes, *or* choose your own set of matrix shapes (just don't make them so large the optimisation takes forever).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "45af1fe9db09e3555994b73c16063653",
     "grade": false,
     "grade_id": "cell-9fed416acb37ebd2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "## Run sgd_learn(...) in this cell\n",
    "## produce the output theta, unflatten\n",
    "## theta, unflatten = learn(...\n",
    "## LEAVE THIS HERE TO FORCE CONSISTENT RESULTS!\n",
    "np.random.seed(2018)\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if your code worked, then it should be able to predict\n",
    "# what the orientation of the face is, from the image of the face\n",
    "# this should be very close to the faces image plotted above\n",
    "predicted_outputs = [predict(face_inputs[i], theta, unflatten) for i in range(698)]\n",
    "show_faces(face_inputs, np.array(predicted_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3cfe3ed2ae9b8d80f5bfed08cb63e957",
     "grade": true,
     "grade_id": "cell-4471cd37fa703256",
     "locked": true,
     "points": 8,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "predictions = np.array([predict(face_inputs[i], theta, unflatten) for i in range(698)])\n",
    "mse_error = np.sqrt(np.mean((predictions-expected_face_orientations)**2))\n",
    "print(\"Total mean squared prediction error: {error:4f}\".format(error=mse_error))\n",
    "\n",
    "# you get more marks for a more correct answer :)\n",
    "with tick.marks(8):\n",
    "    assert(mse_error<0.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "41b217f0479fee57064d9cc81cebd5e3",
     "grade": true,
     "grade_id": "cell-fd818f625a6301b9",
     "locked": true,
     "points": 6,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "with tick.marks(6):\n",
    "    assert(mse_error<0.25)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "04bff132df418a9d50e5de05ee3a0e54",
     "grade": true,
     "grade_id": "cell-fef03547993b6f12",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "with tick.marks(4):\n",
    "    assert(mse_error<0.1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "19c37813290a389401cc19c9deb4748c",
     "grade": true,
     "grade_id": "cell-3e8c42fe8ea2caae",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "with tick.marks(2):\n",
    "    assert(mse_error<0.02)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of assessed portion\n",
    "\n",
    "If you've got this far, you've managed to build a system which can predict the orientation of the face from a picture of the face. All that was needed was some simple gradient descent, which optimised a function parameterised with a 20656 dimensional vector (the number of elements in `theta`).\n",
    "\n",
    "This is not a perfect solution. It is not robust to noise, or to variations in the face position, scale or rotation. We have no idea if it generalises well to other images of the face than those we trained on. The mapping we used is extremely wasteful, and ignored the fact that pixels which are close together are probably related. All of these things would be fixed in a real deep learning approach, but the the principle remains the same. We create a parameterisable function, then optimise its parameters to align the approximation with some known training examples.\n",
    "\n",
    "# Extra material\n",
    "If you really want to understand what is going on in learning in deep networks, read [colah's blog](http://colah.github.io/posts/2015-08-Backprop/),  another [colah article](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/), and [Nielsen's free book](http://neuralnetworksanddeeplearning.com/), or [Deep learning from scratch](http://www.deepideas.net/deep-learning-from-scratch-i-computational-graphs/). You don't need to know **any** of this for this lab though!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Synthesizing faces [optional]\n",
    "We have learned a mapping from face images to face orientations. We can equally well go the other way; from face orientations to face images. Above, we built a face orientation recogniser. We can also build a face orientation image *synthesizer*, that will take a 2D vector and predict a face image. Implement this.  This is a *trivial* modification of what has already been implemented; but you will need a different set of matrix shapes to map from 2D up to a 1024D vector.\n",
    "\n",
    "Write code to implement the face synthesizer. This should give you a vector `syn_theta` representing a transform from 2D orientation space to 1024D face image space, and the corresponding unflatten, so that `predict` is able to generate new synthetic faces.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1adeb367d033a454be77fe97242c4069",
     "grade": false,
     "grade_id": "cell-bb9ac8db61044e6a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the results as an animation\n",
    "# the images here will be synthesized by the network\n",
    "# they will not use the original image data!\n",
    "frames = 32\n",
    "# synthesize the head looking left/right, up/down, then moving in a circle\n",
    "angles = np.linspace(-np.pi, np.pi, frames)\n",
    "positions_a = np.stack([np.cos(angles)*0, np.sin(angles)*0.05]).T\n",
    "positions_b = np.stack([np.cos(angles)*0.3, np.sin(angles)*0]).T\n",
    "positions_c = np.stack([np.cos(angles)*0.3, np.sin(angles)*0.05]).T\n",
    "positions = np.concatenate([positions_a, positions_b, positions_c])\n",
    "predicted_inputs = np.array([predict(pos, syn_theta, unflatten) for pos in positions]).reshape(-1,32,32)\n",
    "ia.show_gif(predicted_inputs, width=\"100px\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced [optional]\n",
    "It is possible to learn a mapping from images to 2D positions *without* training the network with known face orientations. In other words, find a mapping from images to some 2D \"face orientation\" just by looking at the images alone.\n",
    "\n",
    "This can be done with an **autoencoder**; where the function learns a compressive mapping of the inputs through a **bottleneck layer** back to a (noisy) reconstruction of the original inputs.\n",
    "\n",
    "You can do this using a set of matrices which goes from 1024 dimensions down through a number of transformations to 2 dimensions, then back up to 1024 dimensions, and setting the loss to be the difference *between the input and the predicted input*.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    (input) 1024D -> 100D -> 20D -> 2D ->  20D -> 100D -> 1024D (reconstructed input)\n",
    "                                   ^ bottleneck layer\n",
    "\n",
    "Then, you can predict what happens in the \"middle\" of the transformation where the projection has been forced down to 2D. This is a 2D \"explanation\" of the data, and will hopefully capture the orientation of the face somehow. If you attempt this, you will need to read up on autoencoders before you will be able to make progress.\n",
    "\n",
    "The function below is very useful for partially evaluating a network:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_predict(x, theta, unflatten, from_to):\n",
    "    # evaluate from layer from_to[0] to from_to[1]\n",
    "    for w in unflatten(theta)[from_to[0]:from_to[1]]:  \n",
    "        x = w.T @ np.tanh(x + 0.1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f472b180dd1d01a5d8566c368136fe3c",
     "grade": false,
     "grade_id": "cell-5ffba9fc36ab6631",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "be843ca1ee738d92d31d0b0e9283bdaa",
     "grade": true,
     "grade_id": "cell-465e3ba1c0b05a74",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "posns = [partial_predict(x, auto_theta, auto_unflatten, (0,2)) for x in face_inputs]\n",
    "poses = np.array(posns)\n",
    "poses = posns - np.mean(poses, axis=0)\n",
    "show_faces(face_inputs, poses/np.array([2.2, 10.2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/face_orientation.png\" width=\"100%\">\n",
    "This image was generated from the face data without providing any information on the expected output  face orientations. The orientations have a random offset (about 240 degrees), but consistently recover the variation in the face orientation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# Submission instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking your work\n",
    "## Mark summary\n",
    "You should check the marks you've got before submitting. To do this, \n",
    "* Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and matriculation number at the top.\n",
    "* SAVE THE NOTEBOOK, \n",
    "* Go to `Cell/Restart and Run All` in the menu.\n",
    "* Check the output of the cell here.\n",
    "\n",
    "Note that this is an estimated mark, and if you don't do the above procedure *carefully* you may get nonsense estimates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick.summarise_marks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting the submission\n",
    "* **WARNING**: If you do not submit the correct file, you will not get any marks.\n",
    "* Submit this file **only** on Moodle. It will be named `lab_<xxx>.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Penalties (only for assessed labs)\n",
    "<font color=\"red\">\n",
    "    \n",
    "**Malformatted submissions**\n",
    "</font>\n",
    "These assignments are processed with an automatic tool; failure to follow instructions *precisely* will lead to you automatically losing two bands in grade regardless of whether the work is correct (not to mention a long delay in getting your work back). **If you submit a file without your work in it, it will be marked and you will get 0 marks.**\n",
    "\n",
    "<font color=\"red\">**Late submission**</font>\n",
    "Be aware that there is a two band penalty for every *day* of late submission, starting the moment of the deadline.\n",
    "\n",
    "<font color=\"red\">\n",
    "    \n",
    "**Plagiarism**\n",
    "</font> Any form of plagiarism will be subject to the Plagiarism Policy. The penalties are severe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext_format_version": "1.0",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
